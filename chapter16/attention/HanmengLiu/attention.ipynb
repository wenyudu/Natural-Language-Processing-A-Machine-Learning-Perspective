{"cells":[{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00000-0cddf6c1-c099-43fe-b40a-5fdd502766af","output_cleared":false,"source_hash":"d5b52fd2","execution_millis":300,"execution_start":1605667546827},"source":"# Start writing code here...\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable","execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00001-bfcc3a4c-f453-487f-a47e-d85c7be7d943","output_cleared":false,"source_hash":"dc4ef6be","execution_start":1605668169041,"execution_millis":0},"source":"class Encoder(nn.Module):\n    def __init__(self, input_size, hidden_size, bidirectional=True):\n        super(Encoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.input_size = input_size\n        self.bidirectional = bidirectional\n\n        self.lstm = nn.LSTM(input_size, hidden_size, bidirectional=bidirectional)\n\n    def forward(self, inputs, hidden):\n        output, hidden = self.lstm(inputs.view(1, 1, self.input_size), hidden)\n        return output, hidden\n\n    def init_hidden(self):\n        return (torch.zeros(1+int(self.bidirectional), 1, self.hidden_size), \n        torch.zeros(1+int(self.bidirectional), 1, self.hidden_size))","execution_count":2,"outputs":[]},{"cell_type":"code","source":"class AttentionDecoder(nn.Module):\n    def __init__(self, hidden_size, output_size, vocab_size):\n        super(AttentionDecoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n\n        self.attn = nn.Linear(hidden_size + output_size, 1)\n        self.lstm = nn.LSTM(hidden_size + vocab_size, output_size)\n        self.final = nn.Linear(output_size, vocab_size)\n\n    def init_hidden(self):\n        return (torch.zeros(1, 1, self.output_size),\n        torch.zeros(1,1, self.output_size))\n\n    def forward(self, decoder_hidden, encoder_outputs, input):\n        weights = []\n        for i in range(len(encoder_outputs)):\n            print(decoder_hidden[0][0].shape)\n            print(encoder_outputs[0].shape)\n            weights.append(self.attn(torch.cat((decoder_hidden[0][0],\n            encoder_outputs[i]), dim=1)))\n        \n        normalized_weights = F.softmax(torch.cat(weights, 1), 1)\n\n        attn_applied = torch.bmm(normalized_weights.unsqueeze(1), encoder_outputs.view(1, -1, self.hidden_size))\n\n        input_lstm = torch.cat((attn_applied[0], input[0]), dim=1)\n\n        output, hidden = self.lstm(input_lstm.unsqueeze(0), decoder_hidden)\n\n        output = self.final(output[0])\n\n        return output, hidden, normalized_weights","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00002-d99fe289-a5ed-4524-a327-d55ed957d3d0","output_cleared":false,"source_hash":"be4c962a","execution_start":1605669233869,"execution_millis":0},"outputs":[],"execution_count":3},{"cell_type":"code","source":"bidirectional = True\nc = Encoder(10, 20, bidirectional)\na, b = c.forward(torch.randn(10), c.init_hidden())\nprint(a.shape)\nprint(b[0].shape)\nprint(b[1].shape)\n\nx = AttentionDecoder(20 * (1+bidirectional), 25, 30)\ny, z, w = x.forward(x.init_hidden(), torch.cat((a,a)), torch.zeros(1, 1, 30))\nprint(y.shape)\nprint(z[0].shape)\nprint(z[1].shape)\nprint(w)","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00003-acdfe0d7-a64c-42f0-8c75-04377f4e2b21","output_cleared":false,"source_hash":"af1c1ea7","execution_start":1605678802265,"execution_millis":0},"outputs":[{"name":"stdout","text":"torch.Size([1, 1, 40])\ntorch.Size([2, 1, 20])\ntorch.Size([2, 1, 20])\ntorch.Size([1, 25])\ntorch.Size([1, 40])\ntorch.Size([1, 25])\ntorch.Size([1, 40])\ntorch.Size([1, 30])\ntorch.Size([1, 1, 25])\ntorch.Size([1, 1, 25])\ntensor([[0.5000, 0.5000]], grad_fn=<SoftmaxBackward>)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00004-5a950af5-ec3a-4851-a86b-9cb540e88dba"},"outputs":[],"execution_count":null}],"nbformat":4,"nbformat_minor":2,"metadata":{"orig_nbformat":2,"deepnote_notebook_id":"3ddd6259-4b0b-4700-850d-d657cf24b280","deepnote_execution_queue":[]}}